# AnomalyDetection 三種做法


1. 無監督異常值檢測 Unsupervised Outlier Detection
	訓練數據（未標記）包含正常和異常觀察。
	該模型在擬合過程中識別異常值。
	當異常值被定義為數據中低密度區域中存在的點時，將採用這種方法。
	任何不屬於高密度區域的新觀測值都被視為異常值。

2. 半監督新穎性檢測 Semi-supervised Novelty Detection
	訓練數據僅包含描述正常行為的觀察結果。
	該模型適合訓練數據，然後用於評估新的觀察結果。
	當異常值被定義為與訓練數據分佈不同的點時，就會採用這種方法。
	任何與閾值內的訓練數據不同的新觀察結果，即使它們形成高密度區域，也被視為異常值。

3. 監督異常值分類 Supervised Outlier Classification
	每個觀察的基本事實標籤（內點與外點）是已知的。
	該模型適用於不平衡的訓練數據，然後用於對新觀察結果進行分類。
	當基本事實可用時採用這種方法，並且假設異常值將遵循與訓練集中相同的分佈。
	使用該模型對任何新觀察結果進行分類。

[參考來源: PYOD 1.0.7 Documentation](https://pyod.readthedocs.io/en/latest/relevant_knowledge.html#)

## 1. Unsupervised Outlier Detection SOP
* 探針 = 特徵 = feature = X
* 以下設定值的參數建議是在每分鐘有1筆資料的情形下
----
1. 定義異常（想要算法抓出什麼異常）

2. 歷史資料有多少異常點能用？
多 > 用監督式異常偵測方法（此篇不說明）
少 > 非監督式異常偵測方法

3. 確認手上有的探針數量

4. 非監督式學習方法（例如: [GMM](https://pyod.readthedocs.io/en/latest/index.html))

5. 算法當中參數設定 contamination >>> 假設訓練資料及內有多少資料不正常
  （因亦常在資料當中都算少數, 通常都預抓 0.000）實際情形還是要依照資料的異常比例來設定

6. 每個特徵做 Sliding Window（建議值: 30）
    此步驟的目的是參考當下外，也把過去點納進來看，讓後面餵到模型時候是看該探針的 Pattern 是否有跑掉。

7. 特徵轉化成異常分數（該點相對於資料多離群）

8. 將每個特徵用畫圖方式畫出異常點前後（建議值: 前 120 後 60），遍歷所有特徵，找是否有特徵在異常點發生前有異常分數飆高的情形。

9. 若找到有上述的異常點則繼續往下，否則需要回到 2 或 3回到 4 調整算法參數or 回到 5 重做不同的 Window Size 資料若上述方法行不同，可能是現有探針無法反應該 Y，應回到第 2 步驟確認是否有其他探針

10. 將在異常點前有反應的探針整理出來，設為有效探針，每個探針切門檻值當作告警線，將線反推是否有其他未標記的時段，將這些時段整理出來和 BU 確認是否是屬於未知異常

11. 透過 Step. 10 反覆調整告警線，將這些有效探針設計 Voting 或是權重的方式擬合 Y 即完成初版告警模型
